# Image Processing

This repository contains the scripts to preprocess the images shared by NIH-NEI.

The processed images can be used as input to the model in NIH-NEI/ML-Image-Segmentation

# Repo Contents

## Preprocess

The script `preprocess.py` labels and creates segmentation maps from a given image. It outputs 4 files:
- <image_name>_{left,right}.json: Two sections of the original image are cropped and labeled. These files are `labelme`
compatible JSON files.
- <image_name>_{left,right}_label.png: These files are the segmentation maps corresponding to the images above.

Usage:

`python preprocess.py </path/to/image> </path/to/output/dir>`

Note: The script assumes that given the path to an input image, a corresponding CSV files with the labels for each layer will
be present in the same directory.

## HDF5 file

The script `generate_dataset.py` generates a single hdf5 file. Usage:

`python generate_dataset.py </path/to/input/dir> </path/to/output/hdf5/file>`

The hdf5 file will contain 3 datasets:
- x: Original images
- y: Segementation maps of `x`
- image_names: The path to the image files corresponding to `x`

For example:

`python3 generate_dataset.py ../images/training/ example-output/training_dataset.hdf5`

## Generate Datasets

### Training

This script creates a training set by specifying the directories where the training and validation images live. Usage:

`python3 generate_training_dataset.py <path/to/training/hdf5> <path/to/validation/hdf5> <path/to/output_file_name>`

For example:

`python3 generate_training_dataset.py ../images/training/ ../images/validation/ ../train_dataset`

### Testing

The script takes a dataset generated by `generate_dataset.py` script and converts it to a `testing_dataset.py`. Usage:

`python3 generate_test_dataset.py <path/to/test/dir> <path/to/output_file_name>`

For example:

`python3 generate_test_dataset.py ../images/testing/ example-output/test_dataset.hdf5`


# Environment Dependencies

The file `requirements.txt` contains the list of dependencies. Can be used to create the environment with:

`conda create --name <env_name> --file requirements.txt`