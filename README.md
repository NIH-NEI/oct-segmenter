# Image Processing

This repository contains the scripts to preprocess the images shared by NIH-NEI.

The processed images can be used as input to the model in NIH-NEI/unet

## Dependencies

### MacOS

```
brew install pyqt
```


## How to generate datasets for Unet

The following scripts assume that the user already has done the partition for the images that will be used for training, validation and testing.

### Training

`generate_training_dataset.py` creates a training set by specifying the directories where the training and validation images live. The script will walk recursively inside the tree and include all images that it finds along the way.  The script takes the following parameters:
- `<path/to/dir/with/training/images>`: This is the root directory to pick images (`.tiff`, `.bmp` files) that will be used for training.
- `<path/to/dir/with/validation/images>`: This is the root directory to pick images (`.tiff`, `.bmp` files) that will be used for validation.
- `<path/to/output_file_name>`: Name of the generated HDF5 file.

Usage:

`python3 generate_training_dataset.py <path/to/training/hdf5> <path/to/validation/hdf5> <path/to/output_file_name>`

For example:

`python3 generate_training_dataset.py ../images/training/ ../images/validation/ ../train_dataset`


#### Notes related to images sent by Haohua

- It is recommended to use images from different dates to keep the dataset balanced.


### Testing

The script takes a dataset generated by `generate_dataset.py` script and converts it to a `testing_dataset.py`. Usage:

`python3 generate_test_dataset.py <path/to/test/dir> <path/to/output_file_name>`

For example:

`python3 generate_test_dataset.py ../images/testing/ example-output/test_dataset.hdf5`

## Post-processing

The script `merge_images.py` merges the original image withe the segmentation plots from the model evaluation/prediction. Usage:

`python3 merge_image.py <path/to/original/image> <path/to/left/segment/plot> <path/to/right/segment/plot> <path/to/output_file>`

For example:

`python3 merge_image.py ../images/testing/2019.10.23/508_OD_R_1_0_0000097_RegAvg/001.tiff ../../ML-Image-Segmentation/results/2021-09-21_21_26_25_U-net_mice_oct/no\ aug_testing_dataset.hdf5/image_6/seg_plot.png ../../ML-Image-Segmentation/results/2021-09-21_21_26_25_U-net_mice_oct/no\ aug_testing_dataset.hdf5/image_7/seg_plot.png mice4.png`

# Environment Dependencies

The file `requirements.txt` contains the list of dependencies. Can be used to create the environment with:

`conda create --name <env_name> --file requirements.txt`


# Other Information

## Repo Contents

## Preprocess

The script `preprocess.py` labels and creates segmentation maps from a given image. It outputs 4 files:
- <image_name>_{left,right}.json: Two sections of the original image are cropped and labeled. These files are `labelme`
compatible JSON files.
- <image_name>_{left,right}_label.png: These files are the segmentation maps corresponding to the images above.

Usage:

`python preprocess.py </path/to/image> </path/to/output/dir>`

Note: The script assumes that given the path to an input image, a corresponding CSV files with the labels for each layer will
be present in the same directory.

## HDF5 file

The script `generate_dataset.py` generates a single hdf5 file. Usage:

`python generate_dataset.py </path/to/input/dir> </path/to/output/hdf5/file>`

The hdf5 file will contain 3 datasets:
- x: Original images
- y: Segementation maps of `x`
- image_names: The path to the image files corresponding to `x`

For example:

`python3 generate_dataset.py ../images/training/ example-output/training_dataset.hdf5`

